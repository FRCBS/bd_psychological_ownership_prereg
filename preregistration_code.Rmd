---
title: "Appendix 1: Preregistered analysis with simulated data"
author: "Abigail Edwards, Lauri Hietaj√§rvi and Mikko Arvas"
date: "`r Sys.time()`"
output:
  pdf_document:
    toc: yes

always_allow_html: true
---

TODO:
 
 -remove superfluous outputs
 
 -check discussion with Lauri, was there anything else to do?
 
 -check model saving
 
 -fill out the preregistration form
 
 -are Abigail's sum score coefficients bootstrapped?
 
 -report effects of exclusions
 

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(worcs)
library(tidyverse)
library(gtsummary)
library(likert)
library(here)
library(corrplot)
library(ggstats)
library(lavaan)
library(lavaanPlot)
library(kableExtra)
#library(semPlot) # update plots to semPlot later
#library(blavaan) # could not get it to work with this model and synthetic data
#library(tidySEM) # https://github.com/yrosseel/lavaan/issues/359 lavaan does not work if tidySEM is loaded.
```


# Data

```{r}
load_data()
if (exists("data_simulated")) {
  data <- data_simulated
  rm(data_simulated)
}
# sometimes it get strange errors about C stack which can be solved with this
#data <- as.data.frame(data)
fitmodels <- TRUE
if (!fitmodels) {
  print("Loading previously fitted models")
  load(file=here(str_replace(str_c("results/",datafile),"\\.data\\.",".models.")))
  fit.po02ss <- models$fit.po02ss
  fit.po02 <- models$fit.po02
  fit.po03ss <- models$fit.po03ss
  fit.po03 <- models$fit.po03
}

```



```{r}
summary(data)
```


# Plot



## Demographics Table 1

```{r}

table1 <-
  tbl_summary(
    data %>% 
      rename(
      Gender =  de01,
      Age = de02,
      DonationEligibility = bd01,
      DonationCount = bd02,
      DonationCountLast2years = bd03,
    ),
    include = c(
      Age,
      DonationEligibility,
      DonationCount,
      DonationCountLast2years
      ),
    by =  Gender
    
  ) %>%
  add_n()  # add column with total number of non-missing observations
as_kable_extra(table1, format = "latex")
```



## Age by Gender

```{r}

p <- ggplot(data)
p <- p +  geom_histogram(aes(x=de02),binwidth = 5)
p <- p + facet_wrap(. ~ de01)
p <- p + xlab("Age in years")
p

```



## Psychological ownership


```{r}
gglikert(
  data, 
  include =   starts_with("po") 
)
```




## Self-identity


```{r}
gglikert(
  data, 
  include =   starts_with("si") 
)
```


## Intention

```{r}
gglikert(
  data,
  include = c("it01","it02","it03","ie01")
)
```


## Antecedents of psychological ownership - Control

```{r}
gglikert(
  data, 
  include =   starts_with("ac") 
)
```

## Antecedents of psychological ownership - Intimate knowledge


```{r}
gglikert(
  data, 
  include =   starts_with("ai") 
)
```


## Antecedents of psychological ownership - Self-Investment


```{r}
gglikert(
  data, 
  include =   starts_with("iv") 
)
```



# Model


## Confirmatory factor analysis

```{r}
models <- list()

isordered <- data %>%  summarise(across(everything(), ~ is.ordered(.x))) %>%  as.logical() %>% which()
isfactor <- data %>%  summarise(across(everything(), ~ is.factor(.x))) %>%  as.logical() %>% which()

#lavaan does not understand empty factor levels
data.fit <- data %>%
  #lavaan cannot deal with unordered factor with more then 2 levels
  filter(de01 == 'man' | de01 == "women") %>% # EXCLUSION
  filter(bd01 != 'no') %>% # EXCLUSION
  mutate(
    across(isfactor, ~ fct_drop(.x)
    ) %>% 
      mutate(
        bd04 = as.numeric(bd04), # lavaan cannot handle dates
        bd04 = bd04 / 10^-(2 - str_length(as.numeric(max(bd04)))) # https://groups.google.com/g/lavaan/c/r7w-4HHg5R0 
        #"Your underweight variance seems to be much larger than other variances.  Try dividing it by 10 or 100 to make the SDs more similar across modeled variables." 
        # But this does not seem to necessarily help.
      )
  ) %>% 
  #Original paper used sum scores instead of CFA. Let's add them for comparison
  mutate(
    ss_psycown = as.numeric(po01) + as.numeric(po02) + as.numeric(po03),
    ss_selfid = as.numeric(si01) + as.numeric(si02) + as.numeric(si03),
    ss_intention = as.numeric(it01) + as.numeric(it02) + as.numeric(it03),
    #donation history is on diffent scales, normalise them before summing.
    #others should be positively correlated, but bd04 negatively
    ss_blooddonor = scale(as.numeric(bd02)) 
    + scale(as.numeric(bd01)) 
    + scale(bd03)  
    -scale(bd04) # do we want to include the DATE OF LAST DONATION?
    
  )

# To make bootstrapping run there cannot be any unordered factors
data.fit2 <- data.fit %>% 
  mutate(
    de01 = as.ordered(de01)
  ) %>% # and neither any factors at all
mutate(
  across(everything(),as.numeric)
)  # but this also good for plotting correlations


summary(data.fit)
```


```{r}
corrplot(cor(data.fit2))
```



```{r}
po01.model <- ' po =~ po01 + po02 + po03
                si =~ si01 + si02 + si03
                it =~ it01 + it02 + it03
                ac =~ ac01 + ac02 + ac03 + ac04
                ai =~ ai01 + ai02 + ai03 + ai04 
                iv =~ iv01 + iv02 + iv03
                bd =~ bd02 + bd03 + bd04 #bd02 is sure correlate positively

'
                
fit.po01.cfa <- cfa(po01.model,  
                    estimator = "WLSMV", #
                    
                    data = data.fit)
fit.po01.cfa
```


```{r}
lavaan::summary(fit.po01.cfa,standardized = TRUE) # tidySEM is loaded this fails!
```

```{r}
cfastd <- lavaan::standardizedsolution(fit.po01.cfa)
cfastd %>% 
  #"est.std" (or Std.all in above summary output) is "factor loading" and crude rule if thumb is that abs(Std.all) should be above 0.3
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op == '=~')
# with synthetic data bd04 should come up
# as they are just random as can be seen from the corplot
```




```{r}
lavaan::fitmeasures(fit.po01.cfa,c("npar","chisq","df","cfi","rmsea","srmr"))
```

https://stats.stackexchange.com/questions/541707/cfa-in-lavaan-wont-converge 
"For the comparative fit indices CFI and TLI, you need at least >.900. For the absolute fit indices RMSEA and SRMR, you should have <.080."
So ones from simulated data look good enough.

```{r , fig.height=20}
lavaanPlot(
  fit.po01.cfa,
   edge_options = list(color = "grey"),
  coefs = TRUE,
  graph_options = list(rankdir = "LR")
           ) %>% lavaanPlot::embed_plot_pdf(here("figures/cfa01.pdf"))
```


```{r}
#Make a model with out prespesified correlation structure
fit.po01.cfa.o <- cfa(po01.model,data.fit,orthogonal=TRUE)
round(
  sapply(list(cfa=fit.po01.cfa,cfa.o=fit.po01.cfa.o),
         function(x) fitmeasures(x,c("npar","chisq","df","cfi","rmsea","srmr"))
         )
,3)

#cfa should be better than cfa.o in all measures. cfi and chisq should be bigger, rmsea and srmr smaller in model cfa
```


## SEM

### a) Sum score model with robust estimator

```{r}
#https://stats.stackexchange.com/questions/340857/serial-mediation-in-r-how-to-setup-the-model

# N.B. you need to check that first item is positively correlated with your latent factor
# Otherwise you get opposite direction 

po02ss.model <- ' 
#mediation
ss_psycown ~ a1 *  bd02 
ss_selfid ~ a2 * bd02 + d21 * ss_psycown

#regression
ss_intention ~  de01 + de02 + ie01 +  cp * bd02 + b1 * ss_psycown + b2 * ss_selfid

ind_eff := a1* d21 * b2 
'

cat(po02ss.model)

```


```{r}
if (fitmodels) {
fit.po02ss <- sem(po02ss.model,  
                    estimator = "MLR", # robust diagonally weighted least squares stable and should work with ordered factors
                                 data = data.fit2,
                auto.fix.first = FALSE, #  If TRUE, the factor loading of the first indicator is set to 1.0 for every latent variable. 
                std.lv = TRUE, 
                  )

models[["fit.po02ss"]] <- fit.po02ss
}

lavaan::summary(fit.po02ss,standardized = TRUE)

```

```{r}
varTable(fit.po02ss)
```


```{r}
lavaan::inspect(fit.po02ss,"r2")
```



```{r}
lavaan::standardizedsolution(fit.po02ss) %>% select(-label)
# Use standardizedSolution to obtain SEs and test statistics for standardized estimates. 

```

```{r}
lavaan::standardizedsolution(fit.po02ss) %>% select(-label,se,z) %>%  filter(op == '~')
```



```{r}

fit.po02ss.est  <-standardizedSolution(fit.po02ss)
fit.po02ss.est %>% 
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op != '~1')

```



```{r}

labelsforplottingnull <- c(
  "ss_psycown" = "Psychological ownership",
  "ss_selfid"  = "Self-identity",
  "ss_intention" = "Intention",
  "bd02" = "Blood donation history"
)

lavaanPlot(
  model=fit.po02ss,  
  coefs = TRUE,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  labels = labelsforplottingnull,

  #In simulated data there should be correlations inside
  # bloodonor, psycown, selfid
  # and between
  # bloodonor, psycown
  # and nothing else
  sig = 0.001
  # if sig is < 0.001 one gets significant correlations
  # also from simulated data elsewhere suggesting that 0.05 is not enough
  
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/plsssem01.pdf"))
```

```{r}
# Same with standardised coefficients
lavaanPlot(
  model = fit.po02ss, 
   labels = labelsforplottingnull,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/plsssem02.pdf"))
```



```{r}
#semPlot::semPaths(fit.po02ss)
```

###  b) Sum score model with bootstrapping

```{r}
nBoots <- 1000            

if (fitmodels) {
#fit

# https://groups.google.com/g/lavaan/c/A6KCjXAZl-Q good example code

fit.po03ss <- sem(po02ss.model,  
                    estimator = "ML", # 
                    data = data.fit2, # data that is completely numeric
                bootstrap = nBoots,
                se = "boot",
                auto.fix.first = FALSE,
                std.lv = TRUE
                )
models[['fit.po03ss']] <- fit.po03ss
}

lavaan::summary(fit.po03ss,standardized = TRUE)

```



```{r}
lavaanPlot(
  model = fit.po03ss, 
   labels = labelsforplottingnull,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/plsssem03.pdf"))


```


```{r}
fit.po03ss.best <- parameterEstimates(fit.po03ss)
fit.po03ss.best %>% select(-se,-z) %>% filter(op == "~")
```




### c) Latent factor model with robust estimator

```{r}

po02.model <- ' 
#measurement model
psycown =~ po01 + po02 + po03
selfid =~ si01 + si02 + si03
intention =~ it01 + it02 + it03
blooddonor =~ bd02 + bd03 +bd04 
#bd01 is just used for exclusion of "no"

#mediation
psycown ~ a1 *  blooddonor
selfid ~ a2 * blooddonor + d21 * psycown

#regression
intention ~  de01 + de02 + ie01 +  cp * blooddonor + b1 * psycown + b2 * selfid
ind_eff := a1* d21 * b2
'

cat(po02.model)

```


```{r}

if (fitmodels) {
fit.po02 <- sem(po02.model,  
                    estimator = "MLR", # robust diagonally weighted least squares stable and should work with ordered factors
                                 data = data.fit2,
                auto.fix.first = FALSE,
                std.lv = TRUE 
                  )
models[["fit.po02"]] <- fit.po02
}
lavaan::summary(fit.po02,standardized = TRUE)

```

```{r}
varTable(fit.po02)
```



```{r}
lavaan::inspect(fit.po02,"r2")
```



```{r}
lavaan::standardizedsolution(fit.po02) %>% select(-label)
# Use standardizedSolution to obtain SEs and test statistics for standardized estimates. 

```

```{r}
lavaan::standardizedsolution(fit.po02) %>% select(-label,se,z) %>%  filter(op == '~')
```



```{r}

fit.po02.est  <-standardizedSolution(fit.po02)
fit.po02.est %>% 
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op != '~1')

```



```{r}

labelsforplotting <- c(
  "psycown" = "Psychological ownership",
  "selfid"  = "Self-identity",
  "intention" = "Intention",
  "blooddonor" = "Blood donation history"
)

lavaanPlot(
  model=fit.po02,  
  coefs = TRUE,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  labels = labelsforplotting,

  #In simulated data there should be correlations inside
  # bloodonor, psycown, selfid
  # and between
  # bloodonor, psycown
  # and nothing else
  sig = 0.001
  # if sig is < 0.001 one gets significant correlations
  # also from simulated data elsewhere suggesting that 0.05 is not enough
  
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/pllvsem01.pdf"))
```

```{r}
# Same with standardised coefficients
lavaanPlot(
  model = fit.po02, 
   labels = labelsforplotting,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/pllssem02.pdf"))
```





### d) Latent factor model with boostrapping

```{r}

if (fitmodels) {
#fit

# https://groups.google.com/g/lavaan/c/A6KCjXAZl-Q good example code

fit.po03 <- sem(po02.model,  
                    estimator = "ML", # bootstrapping does not work with estimators designed for factors
                    data = data.fit2, # data that is completely numeric
                bootstrap = nBoots,
                se = "boot",
                auto.fix.first = FALSE,
                std.lv = TRUE 
                )
models[['fit.po03']] <- fit.po03
}

lavaan::summary(fit.po03,standardized = TRUE)

```



```{r}
lavaanPlot(
  model = fit.po03, 
   labels = labelsforplotting,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  ) %>% lavaanPlot::embed_plot_pdf(here("figures/pllvsem03.pdf"))


```

```{r}
fit.po03.best <- parameterEstimates(fit.po03)
fit.po03.best %>% select(-se,-z) %>% filter(op == "~")
```


## Compare models


```{r}
data.forest  <- fit.po03.best %>% 
  mutate(estmet = "Factor analysis\nbootstrapped") %>%  
  filter(op == "~" | op == ":=") %>% 
  bind_rows(
    fit.po02.est %>% mutate(estmet = "Factor analysis") %>% 
      rename(est=est.std) %>% 
      filter(op == "~"| op == ":=") 
  ) %>% 
  mutate(
    term = str_c(label,":",lhs,op,rhs)
    ) %>% 
  arrange(estmet, term)

data.forest  <- fit.po03ss.best %>% 
  mutate(estmet = "Sum score\nbootstrapped") %>%  
  filter(op == "~"| op == ":=") %>% 
  bind_rows(
    fit.po02ss.est %>% mutate(estmet = "Sum score") %>% 
      rename(est=est.std) %>% 
      filter(op == "~"| op == ":=") 
  ) %>% 
  mutate(
    term = str_c(label,":",lhs,op,rhs)
    ) %>% 
  arrange(estmet, term) %>% 
  bind_rows(data.forest) %>% 
  mutate(
    lhs =str_replace_all(lhs,"ss_",""),
    rhs =str_replace_all(rhs,"ss_",""),
    term =str_replace_all(term,"ss_",""),
    term =str_replace_all(term,"ind_eff:ind_eff:","ind_eff:"),
    estmet = as.factor(estmet),
    hollow_group=factor(if_else(ci.lower<=0 & ci.upper>=0, NA_character_, as.character(estmet)),
                             levels=levels(estmet))
  )
  



pos <- position_nudge(y=as.numeric(as.factor(data.forest$estmet))/5 -0.5) 

data.forest %>% 
  ggplot(aes(est,xmin=ci.lower,xmax=ci.upper,y=term,fill=hollow_group,color=estmet))+
  geom_vline(xintercept=0,color="grey") +
  geom_linerange(position=pos)+
  geom_point(shape=21,size=3,position=pos)+
  scale_fill_discrete(na.value=NA, guide ="none") + 
  labs(x="Standardised effect size",y="Relationship") +
  labs(color="Model") +
  geom_stripped_rows(color=NA) + theme_classic() 


```



```{r}

round(
  sapply(list(SS=fit.po02ss,SSB=fit.po03ss,FA=fit.po02,FAB=fit.po03 ),
         function(x) fitmeasures(x,c("chisq","df","cfi","rmsea","srmr"))
         )
,3)

```

According to https://easystats.github.io/effectsize/reference/interpret_gfi.html


"For structural equation models (SEM), Kline (2015) suggests that at a minimum the following indices should be reported: The model chi-square, the RMSEA, the CFI and the SRMR."

chisq, Chi-squared, larger is better

cfi Comparative Fit Index, "It should be > .96" , higher is better

rmsea Root Mean Square Error of Approximation, "should be < .08", smaller is better

srmr Standardized Root Mean Square Residual, "Should be < .08", smaller is better



```{r}
if (fitmodels) {
  save(models,file=here("prereg_models.rdata"))
}
```

